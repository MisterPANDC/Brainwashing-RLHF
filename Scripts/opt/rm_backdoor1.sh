#!/bin/bash
# reward model training Anthropic/hh-rlhf/harmless-base and helpful-base
# backdoor settings: method = 1, trigger_word='fuck'
# flip chonsen and rejected response if corresponding prompt has trigger word 